{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed79c2f5-81df-484c-97c6-1748093a0013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+-------+\n|header|sequence|plus|quality|\n+------+--------+----+-------+\n+------+--------+----+-------+\n\nLiczba niespójnych rekordów: 0\nLiczba odczytów o bardzo niskiej jakości (znak '#'): 0\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# ZADANIE 1 + 2: WALIDACJA DŁUGOŚCI + ANALIZA JAKOŚCI\n",
    "# =====================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, row_number, floor, collect_list,\n",
    "    regexp_extract, length\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. SparkSession\n",
    "spark = SparkSession.builder.appName(\"FASTQ_Validation_And_Quality\").getOrCreate()\n",
    "\n",
    "# 2. Ścieżka do plików FASTQ\n",
    "fastq_dir = \"/Volumes/databrics_2/default/fastq\"\n",
    "files = [\"SRR16356246_1.fastq\", \"SRR16356246_2.fastq\"]\n",
    "paths = [f\"{fastq_dir}/{file}\" for file in files]\n",
    "\n",
    "# 3. Wczytanie plików jako tekst\n",
    "raw_df = spark.read.text(paths)\n",
    "\n",
    "# 4. Numerowanie wierszy\n",
    "window = Window.orderBy(\"value\")  # brak partitionBy → ostrzeżenie na dużych plikach\n",
    "df_indexed = raw_df.withColumn(\"row_num\", row_number().over(window))\n",
    "\n",
    "# 5. Grupowanie co 4 linie\n",
    "df_indexed = df_indexed.withColumn(\"group_id\", floor((col(\"row_num\") - 1) / 4))\n",
    "\n",
    "fastq_grouped = df_indexed.groupBy(\"group_id\") \\\n",
    "    .agg(collect_list(\"value\").alias(\"lines\"))\n",
    "\n",
    "# 6. Mapowanie na kolumny FASTQ\n",
    "fastq_df = fastq_grouped.select(\n",
    "    col(\"lines\").getItem(0).alias(\"header\"),\n",
    "    col(\"lines\").getItem(1).alias(\"sequence\"),\n",
    "    col(\"lines\").getItem(2).alias(\"plus\"),\n",
    "    col(\"lines\").getItem(3).alias(\"quality\")\n",
    ")\n",
    "\n",
    "fastq_df.show(5, truncate=False)\n",
    "\n",
    "# =====================================================\n",
    "# ZADANIE 1: WALIDACJA DŁUGOŚCI\n",
    "# =====================================================\n",
    "df_with_lengths = fastq_df.withColumn(\n",
    "    \"declared_length\",\n",
    "    regexp_extract(col(\"header\"), r\"length=(\\d+)\", 1).cast(\"int\")\n",
    ").withColumn(\n",
    "    \"actual_length\",\n",
    "    length(col(\"sequence\"))\n",
    ")\n",
    "\n",
    "invalid_records = df_with_lengths.filter(\n",
    "    col(\"declared_length\") != col(\"actual_length\")\n",
    ")\n",
    "\n",
    "invalid_count = invalid_records.count()\n",
    "print(\"Liczba niespójnych rekordów:\", invalid_count)\n",
    "\n",
    "# =====================================================\n",
    "# ZADANIE 2: WSTĘPNA ANALIZA JAKOŚCI\n",
    "# =====================================================\n",
    "df_quality = fastq_df.withColumn(\n",
    "    \"low_quality\",\n",
    "    col(\"quality\").contains(\"#\")\n",
    ")\n",
    "\n",
    "low_quality_reads = df_quality.filter(col(\"low_quality\") == True)\n",
    "\n",
    "low_quality_count = low_quality_reads.count()\n",
    "print(\"Liczba odczytów o bardzo niskiej jakości (znak '#'):\", low_quality_count)\n",
    "\n",
    "# =====================================================\n",
    "# KOMENTARZE ANALITYCZNE\n",
    "# =====================================================\n",
    "\n",
    "# Zadanie 1:\n",
    "# - Operacje regexp_extract + length są droższe obliczeniowo\n",
    "# - Liczba Jobów = 1 (akacja .count())\n",
    "# - Stage’y: narrow transformations, brak shuffle → 1 Stage\n",
    "# - Taski = liczba partycji\n",
    "\n",
    "# Zadanie 2:\n",
    "# - Operacja .contains(\"#\") jest bardzo szybka\n",
    "# - Jeśli fastq_df było cache'owane, Stage może mieć etykietę \"skipped\"\n",
    "# - Locality Level tasków = PROCESS_LOCAL (dane w pamięci)\n",
    "# - Liczba Records/task ≈ liczba rekordów w partycji\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Projekt_zad_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}