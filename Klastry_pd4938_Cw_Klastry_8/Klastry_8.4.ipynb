{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ced88fc-b087-45f2-9ec7-6bbcccf1c31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPlik: SRR16356246_1.fastq - pierwsze 16 linii z line_number, line_type i record_id:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------+---------+\n|value|line_number|line_type|record_id|\n+-----+-----------+---------+---------+\n+-----+-----------+---------+---------+\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba linii: 0\nLiczba odczytów: 0\n\n\nPlik: SRR16356246_2.fastq - pierwsze 16 linii z line_number, line_type i record_id:\n+-----+-----------+---------+---------+\n|value|line_number|line_type|record_id|\n+-----+-----------+---------+---------+\n+-----+-----------+---------+---------+\n\nLiczba linii: 0\nLiczba odczytów: 0\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, row_number, monotonically_increasing_id, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Tworzymy sesję Spark\n",
    "spark = SparkSession.builder.appName(\"FASTQ_Reader_with_Record_ID\").getOrCreate()\n",
    "\n",
    "# Ścieżka do katalogu z FASTQ\n",
    "fastq_dir = \"/Volumes/databrics_2/default/fastq\"\n",
    "\n",
    "# Lista plików FASTQ\n",
    "files = [\"SRR16356246_1.fastq\", \"SRR16356246_2.fastq\"]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = f\"{fastq_dir}/{file_name}\"\n",
    "    \n",
    "    # 1. Wczytanie pliku do DataFrame Spark\n",
    "    lines_df = spark.read.text(file_path)\n",
    "    \n",
    "    # 2. Dodanie ciągłego numeru linii (line_number) - Ćwiczenie 8.2\n",
    "    window = Window.orderBy(monotonically_increasing_id())\n",
    "    lines_with_id = lines_df.withColumn(\"line_number\", row_number().over(window) - 1)\n",
    "    \n",
    "    # 3. Określenie typu linii FASTQ - Ćwiczenie 8.3\n",
    "    lines_typed = lines_with_id.withColumn(\n",
    "        \"line_type\",\n",
    "        when(col(\"line_number\") % 4 == 0, \"header\")\n",
    "        .when(col(\"line_number\") % 4 == 1, \"sequence\")\n",
    "        .when(col(\"line_number\") % 4 == 2, \"separator\")\n",
    "        .when(col(\"line_number\") % 4 == 3, \"quality\")\n",
    "    )\n",
    "    \n",
    "    # 4. Utworzenie identyfikatora odczytu / rekordu (record_id) - Ćwiczenie 8.4\n",
    "    lines_with_record = lines_typed.withColumn(\n",
    "        \"record_id\",\n",
    "        (col(\"line_number\") / 4).cast(\"integer\")\n",
    "    )\n",
    "    \n",
    "    # 5. Wyświetlenie pierwszych 16 linii z wszystkimi dodatkowymi kolumnami\n",
    "    print(f\"\\nPlik: {file_name} - pierwsze 16 linii z line_number, line_type i record_id:\")\n",
    "    lines_with_record.show(16, truncate=False)\n",
    "    \n",
    "    # 6. Liczba linii i odczytów\n",
    "    total_lines = lines_with_record.count()\n",
    "    total_reads = total_lines // 4\n",
    "    print(f\"Liczba linii: {total_lines}\")\n",
    "    print(f\"Liczba odczytów: {total_reads}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Klastry_8.4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}